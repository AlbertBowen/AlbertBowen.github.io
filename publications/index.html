<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Bowen LIU </title> <meta name="author" content="Bowen LIU "> <meta name="description" content="&lt;span&gt;*&lt;/span&gt; denotes equal contribution."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png?67edf8dde1604027c9ee967f940ba89c"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://albertbowen.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Bowen LIU</span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"><span>*</span> denotes equal contribution.</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">SIGCOMM</abbr> </div> <div id="ceio-sigcomm" class="col-sm-8"> <div class="title">CEIO: A Cache-Efficient Network I/O Architecture for NIC-CPU Data Paths</div> <div class="author"> <em>Bowen Liu<sup>*</sup></em> , Xinyang Huang<sup>*</sup> , Qijing Li, <a href="https://zobinhuang.github.io/sec_about/" rel="external nofollow noopener" target="_blank">Zhuobin Huang</a>, Yijun Sun, <a href="https://leewxgit.github.io/index.html" rel="external nofollow noopener" target="_blank">Wenxue Li</a>, <a href="https://snowzjx.me/" rel="external nofollow noopener" target="_blank">Junxue Zhang</a>, Ping Yin, and Kai Chen. </div> <div class="periodical"> <em>In 39th ACM Special Interest Group on Data Communication (<b>SIGCOMM</b>)</em> , 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Efficient Input/Output (I/O) data path between NICs and CPUs/DRAMs is critical for supporting datacenter applications with high-performance network transmission, especially as link speed scales to 100Gbps and beyond. Traditional I/O acceleration strategies, such as Data Direct I/O (DDIO) and Remote Direct Memory Access (RDMA), perform suboptimally due to the inefficient utilization of the Last-Level Cache (LLC). This paper presents CEIO, a novel cache-efficient network I/O architecture that employs proactive rate control and elastic buffering to achieve zero LLC misses in the I/O data path while ensuring the effectiveness of DDIO and RDMA under various network conditions. We have implemented CEIO on commodity SmartNICs and incorporated it into widely-used DPDK and RDMA libraries. Experiments with well-optimized RPC framework and distributed file system under realistic workloads demonstrate that CEIO achieves up to 2.9x higher throughput and 1.9x lower P99.9 latency over prior work.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">SIGCOMM</abbr> </div> <div id="dcp-sigcomm" class="col-sm-8"> <div class="title">Revisiting RDMA Reliability for Lossy Fabrics</div> <div class="author"> <a href="https://leewxgit.github.io/index.html" rel="external nofollow noopener" target="_blank">Wenxue Li</a> , Xiangzhou Liu , Yunxuan Zhang , Zihao Wang, Wei Gu , <a href="https://gaoxiong.site/" rel="external nofollow noopener" target="_blank">Gaoxiong Zeng</a> , Shoushou Ren , Xinyang Huang, <a href="https://weak-mirror-e3c.notion.site/Ren-Zhenghang-Homepage-1c30c86f89468090acedc4c6650e009f" rel="external nofollow noopener" target="_blank">Zhenghang Ren</a>, <em>Bowen Liu</em>, <a href="https://snowzjx.me/" rel="external nofollow noopener" target="_blank">Junxue Zhang</a>, and Kai Chen. </div> <div class="periodical"> <em>In 39th ACM Special Interest Group on Data Communication (<b>SIGCOMM</b>)</em> , 2025 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ATC</abbr> </div> <div id="flb" class="col-sm-8"> <div class="title">FLB: Fine-grained Load Balancing for Lossless Datacenter Networks</div> <div class="author"> Jinbin Hu, <a href="https://leewxgit.github.io/index.html" rel="external nofollow noopener" target="_blank">Wenxue Li</a> , Xiangzhou Liu , Junfeng Wang, <em>Bowen Liu</em>, Ping Yin , Jianxin Wang , Jiawei Huang, and Kai Chen. </div> <div class="periodical"> <em>In 2025 USENIX Annual Technical Conference (<b>ATC</b>)</em> , 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Remote Direct Memory Access (RDMA) over Converged Ethernet (RoCE) cooperating with Priority Flow Control (PFC) has been widely deployed in production datacenters to enable low latency, lossless transmission. At the same time, modern datacenters typically offer parallel transmission paths between any pair of end-hosts, underscoring the importance of load balancing. However, the well-studied load balancing mechanisms designed for lossy datacenter networks (DCNs) are ill-suited for such lossless environments. Through extensive experiments, we are among the first to comprehensively inspect the interactions between PFC and load balancing, and uncover that existing fine-grained rerouting schemes can be counterproductive to spread the congested flows among more paths, further aggravating PFC’s head-of-line (HoL) blocking. Motivated by this, we present FLB, a Fine-grained Load Balancing scheme for lossless DCNs. At its core, FLB employs threshold-free rerouting to effectively balance traffic load and improve link utilization during normal conditions and leverages timely congested flow isolation to eliminate HoL blocking on non-congested flows when congestion occurs. We have fully implemented a FLB prototype, and our evaluation results show that FLB reduces PFC PAUSE rate by up to 96% and avoids HoL blocking, translating to up to 45% improvement in goodput over CONGA+DCQCN and 40%, 36%, 29% and 18% reduction in average flow completion time (FCT) over LetFlow+Swift, MP-RDMA, Proteus+DCQCN and LetFlow+PCN, respectively.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">APNet</abbr> </div> <div id="carc-apnet" class="col-sm-8"> <div class="title">Cache-Aware I/O Rate Control for RDMA</div> <div class="author"> Qijing Li , Xinyang Huang, <em>Bowen Liu</em> , Pengbo Li, <a href="https://snowzjx.me/" rel="external nofollow noopener" target="_blank">Junxue Zhang</a>, and Kai Chen. </div> <div class="periodical"> <em>In 9th Asia-Pacific Workshop on Networking (<b>APNet</b>)</em> , 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Remote Direct Memory Access (RDMA) has become a cornerstone technology in modern datacenter networks due to its high throughput and extremely low latency. However, recent works have revealed that congestion arises in the "last mile" of the RDMA I/O path—–between DRAM and CPU registers–—due to inefficiencies in the memory hierarchy, where severe cache misses and memory bandwidth contention degrade performance. We identify the root cause of this I/O congestion as the speed mismatch between network ingress and CPU processing, which leads to data accumulation and, eventually, Last-Level Cache (LLC) overflow. To address this issue, we propose RhyR, a credit-based rate control mechanism that dynamically aligns network ingress speed with CPU processing speed. Our preliminary evaluation on eRPC over RDMA, a widely used RPC framework, demonstrates that RhyR effectively mitigates I/O congestion, reducing tail latency by up to 1.40x and improving throughput by up to 1.35x compared to prior work.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">OSDI</abbr> </div> <div id="fuseline-osdi" class="col-sm-8"> <div class="title">Enabling Efficient GPU Communication over Multiple NICs with FuseLink</div> <div class="author"> <a href="https://weak-mirror-e3c.notion.site/Ren-Zhenghang-Homepage-1c30c86f89468090acedc4c6650e009f" rel="external nofollow noopener" target="_blank">Zhenghang Ren</a> , Yuxuan Li , Zilong Wang , Xinyang Huang, <a href="https://leewxgit.github.io/index.html" rel="external nofollow noopener" target="_blank">Wenxue Li</a>, Kaiqiang Xu, Xudong Liao, Yijun Sun, <em>Bowen Liu</em>, <a href="https://tianhan4.github.io" rel="external nofollow noopener" target="_blank">Han Tian</a>, <a href="https://snowzjx.me/" rel="external nofollow noopener" target="_blank">Junxue Zhang</a> , Mingfei Wang, <a href="https://zhizhenzhong.com/" rel="external nofollow noopener" target="_blank">Zhizhen Zhong</a> , Guyue Liu , Ying Zhang, and Kai Chen. </div> <div class="periodical"> <em>In Proceedings of the 19th USENIX Symposium on Operating Systems Design and Implementation (<b>OSDI</b>)</em> , 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/axio-project/FuseLink" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Machine learning (ML) clusters stack multiple network interface cards (NICs) within each server to improve GPU communication bandwidth. However, existing systems fall short in fully utilizing NICs because of statically binding GPU traffic to NICs and PCIe bottleneck. This leads to suboptimal performance under imbalanced traffic, such as when GPUs process different LLM serving requests and training models with varying communication pattern. We propose FuseLink to enable efficient GPU communication over multiple NICs. FuseLink extends inter-server network by integrating high-speed intra-server connections, and recognizes GPUs to efficiently relay traffic to idle NICs. We implement FuseLink and integrate it into NCCL, so that ML applications can use FuseLink seamlessly without code modifications. Compared to NCCL with PXN, we verify that FuseLink can achieve 212GBps bandwidth between two inter-server GPUs and bring speedup on producing the first token in LLM model serving by 1.06-2.89, mixture-of-expert (MoE) training by up to 1.3x, and recommendation model training by up to 1.2x.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">S&amp;P</abbr> </div> <div id="edge-unlearning" class="col-sm-8"> <div class="title">Edge Unlearning is Not" on Edge"! An Adaptive Exact Unlearning System on Resource-Constrained Devices</div> <div class="author"> <a href="https://xiaoyushawxia.github.io/homepage/" rel="external nofollow noopener" target="_blank">Xiaoyu Xia</a> , Ziqi Wang, Ruoxi Sun, <em>Bowen Liu</em>, Ibrahim Khalil, and Minhui Xue. </div> <div class="periodical"> <em>In 46th IEEE Symposium on Security and Privacy (<b>S&amp;P</b>)</em> , 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>The right to be forgotten mandates that machine learning models enable the erasure of a data owner’s data and information from a trained model. Removing data from the dataset alone is inadequate, as machine learning models can memorize information from the training data, increasing the potential privacy risk to users. To address this, multiple machine unlearning techniques have been developed and deployed. Among them, approximate unlearning is a popular solution, but recent studies report that its unlearning effectiveness is not fully guaranteed. Another approach, exact unlearning, tackles this issue by discarding the data and retraining the model from scratch, but at the cost of considerable computational and memory resources. However, not all devices have the capability to perform such retraining. In numerous machine learning applications, such as edge devices, Internet-of-Things (IoT), mobile devices, and satellites, resources are constrained, posing challenges for deploying existing exact unlearning methods. In this study, we propose a Constraint-aware Adaptive Exact Unlearning System at the network Edge (CAUSE), an approach to enabling exact unlearning on resource-constrained devices. Aiming to minimize the retrain overhead by storing sub-models on the resource-constrained device, CAUSE innovatively applies a Fibonacci-based replacement strategy and updates the number of shards adaptively in the user-based data partition process. To further improve the effectiveness of memory usage, CAUSE leverages the advantage of model pruning to save memory via compression with minimal accuracy sacrifice. The experimental results demonstrate that CAUSE significantly outperforms other representative systems in realizing exact unlearning on the resource-constrained device by 9.23%-80.86%, 66.21%-83.46%, and 5.26%-194.13% in terms of unlearning speed, energy consumption, and accuracy.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAAI</abbr> </div> <div id="wu2025pfedcs" class="col-sm-8"> <div class="title">PFedCS: A Personalized Federated Learning Method for Enhancing Collaboration among Similar Classifiers</div> <div class="author"> Siyuan Wu, Yongzhe Jia, <em>Bowen Liu</em>, Haolong Xiang, Xiaolong Xu, and <a href="https://cs.nju.edu.cn/douwanchun/index.htm" rel="external nofollow noopener" target="_blank">Wanchun Dou</a> </div> <div class="periodical"> <em>In Proceedings of the AAAI Conference on Artificial Intelligence (<b>AAAI</b>)</em> , 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Personalized federated learning (PFL) has recently gained significant attention for its capability to address the poor convergence performance on highly heterogeneous data and the lack of personalized solutions of traditional federated learning (FL). Existing mainstream approaches either perform personalized aggregation based on a specific model architecture to leverage global knowledge or achieve personalization by exploiting client similarities. However, the former overlooks the discrepancies in client data distributions by indiscriminately aggregating all clients, while the latter lacks fine-grained collaboration of classifiers relevant to local tasks. In view of this challenge, we propose a Personalized Federated learning method for Enhancing Collaboration among Similar Classifiers (PFedCS), which aims at improving the client’s accuracy on local tasks. Concretely, it is achieved by leveraging awareness of the client classifier similarities to address the above problems. By iteratively measuring the distance of the classifier parameters between clients and clustering with each client as a cluster center, the central server adaptively identifies the collaborating clients with similar data distributions. In addition, a distance-constrained aggregation method is designed to generate customized collaborative classifiers to guide local training. As a result, extensive experimental evaluations conducted on three datasets demonstrate that our method achieves state-of-the-art performance.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TMC</abbr> </div> <div id="edgeshield" class="col-sm-8"> <div class="title">EdgeShield: Enabling collaborative DDoS mitigation at the edge</div> <div class="author"> <a href="https://xiaoyushawxia.github.io/homepage/" rel="external nofollow noopener" target="_blank">Xiaoyu Xia</a> , Feifei Chen, Qiang He, Ruikun Luo, <em>Bowen Liu</em>, Caslon Chua, Rajkumar Buyya, and Yun Yang. </div> <div class="periodical"> <em>In IEEE Transactions on Mobile Computing (<b>TMC</b>)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Edge computing (EC) enables low-latency services by pushing computing resources to the network edge. Due to the geographic distribution and limited capacities of edge servers, EC systems face the challenge of edge distributed denial-of-service (DDoS) attacks. Existing systems designed to fight cloud DDoS attacks cannot mitigate edge DDoS attacks effectively due to new attack characteristics. In addition, those systems are typically activated upon detected attacks, which is not always realistic in EC systems. DDoS mitigation needs to be cohesively integrated with workload migration at the edge to ensure timely responses to edge DDoS attacks. In this paper, we present EdgeShield, a novel DDoS mitigation system that leverages edge servers’ computing resources collectively to defend against edge DDoS attacks without the need for attack detection. Aiming to maximize system throughput over time without causing significant service delays, EdgeShield monitors service delays and migrates workloads across an EC system with adaptive mitigation strategies. The experimental results show that EdgeShield significantly outperforms state-of-the-art solutions in both system throughput and service delays.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TAAS</abbr> </div> <div id="liu2024consortium" class="col-sm-8"> <div class="title">A Consortium Blockchain-Based Edge Task Offloading Method for Connected Autonomous Vehicles</div> <div class="author"> <em>Bowen Liu</em> , Hao Tian, Zhijie Shen, Yueyue Xu, and <a href="https://cs.nju.edu.cn/douwanchun/index.htm" rel="external nofollow noopener" target="_blank">Wanchun Dou</a> </div> <div class="periodical"> <em>In ACM Transactions on Autonomous and Adaptive Systems (<b>TAAS</b>)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>In recent years, the proliferation of Connected Autonomous Vehicles(CAV) has revolutionizing the transportation industry. However, these vehicles often face limitations in terms of local computing resources, leading to the need for offloading interactive-intensive application tasks to servers for processing. Traditional paradigm has its limitations in meeting the demands of massive task processing. The combination of Web3.0 and edge computing offers users high-reliable, low-latency, and highly flexible services. Nevertheless, the new paradigm also presents its own challenges such as ensuring privacy data protection, and reducing the time and energy costs associated with task offloading. To tackle these challenges, a edge task offloading framework based on consortium blockchain for CAVs has been developed. Within this framework, a consortium blockchain-based interaction-intensive task offloading method, called CBIToMe, has been designed. CBIToMe specifically addresses the multi-stage nature of interactive-intensive CAV tasks and aims to minimize task completion time and offloading costs, particularly when the waiting time for interaction is uncertain. Additionally, CBIToMe effectively utilizes consortium blockchain technology to safeguard the CAV privacy data. Results from experiments conducted in various scenarios demonstrate that CBIToMe outperforms three representative methods, showcasing its superior performance.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">SPE</abbr> </div> <div id="wu2024edge" class="col-sm-8"> <div class="title">An edge-assisted federated contrastive learning method with local intrinsic dimensionality in noisy label environment</div> <div class="author"> Siyuan Wu , Guoming Zhang, Fei Dai, <em>Bowen Liu</em>, and <a href="https://cs.nju.edu.cn/douwanchun/index.htm" rel="external nofollow noopener" target="_blank">Wanchun Dou</a> </div> <div class="periodical"> <em>In Software: Practice and Experience (<b>SPE</b>)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>The advent of federated learning (FL) has presented a viable solution for distributed training in edge environment, while simultaneously ensuring the preservation of privacy. In real-world scenarios, edge devices may be subject to label noise caused by environmental differences, automated weakly supervised annotation, malicious tampering, or even human error. However, the potential of the noisy samples have not been fully leveraged by prior studies on FL aimed at addressing label noise. Rather, they have primarily focused on conventional filtering or correction techniques to alleviate the impact of noisy labels. To tackle this challenge, a method, named DETECTION, is proposed in this article. It aims at effectively detecting noisy clients and mitigating the adverse impact of label noise while preserving data privacy. Specially, a confidence scoring mechanism based on local intrinsic dimensionality (LID) is investigated for distinguishing noisy clients from clean clients. Then, a loss function based on prototype contrastive learning is designed to optimize the local model. To address the varying levels of noise across clients, a LID weighted aggregation strategy (LA) is introduced. Experimental results on three datasets demonstrate the effectiveness of DETECTION in addressing the issue of label noise in FL while maintaining data privacy.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">SCN</abbr> </div> <div id="liu2023adversarial" class="col-sm-8"> <div class="title">Adversarial Attacks on Large Language Model Based System and Mitigating Strategies: A Case Study on ChatGPT</div> <div class="author"> <em>Bowen Liu</em>, Boao Xiao, Xutong Jiang, Siyuan Cen, Xin He, and <a href="https://cs.nju.edu.cn/douwanchun/index.htm" rel="external nofollow noopener" target="_blank">Wanchun Dou</a> </div> <div class="periodical"> <em>In Security and Communication Networks (<b>SCN</b>)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Machine learning algorithms are at the forefront of the development of advanced information systems. The rapid progress in machine learning technology has enabled cutting-edge large language models (LLMs), represented by GPT-3 and ChatGPT, to perform a wide range of NLP tasks with a stunning performance. However, research on adversarial machine learning highlights the need for these intelligent systems to be more robust. Adversarial machine learning aims to evaluate attack and defense mechanisms to prevent the malicious exploitation of these systems. In the case of ChatGPT, adversarial induction prompt can cause the model to generate toxic texts that could pose serious security risks or propagate false information. To address this challenge, we first analyze the effectiveness of inducing attacks on ChatGPT. Then, two effective mitigating mechanisms are proposed. The first is a training-free prefix prompt mechanism to detect and prevent the generation of toxic texts. The second is a RoBERTa-based mechanism that identifies manipulative or misleading input text via external detection models. The availability of this method is demonstrated through experiments.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CC</abbr> </div> <div id="shen2023game" class="col-sm-8"> <div class="title">A Game Theory-Based COVID-19 Close Contact Detecting Method with Edge Computing Collaboration</div> <div class="author"> Yue Shen, <em>Bowen Liu</em>, <a href="https://xiaoyushawxia.github.io/homepage/" rel="external nofollow noopener" target="_blank">Xiaoyu Xia</a>, Lianyong Qi, Xiaolong Xu, and <a href="https://cs.nju.edu.cn/douwanchun/index.htm" rel="external nofollow noopener" target="_blank">Wanchun Dou</a> </div> <div class="periodical"> <em>In Computer Communications (<b>CC</b>)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>People all throughout the world have suffered from the COVID-19 pandemic. People can be infected after brief contact, so how to assess the risk of infection for everyone effectively is a tricky challenge. In view of this challenge, the combination of wireless networks with edge computing provides new possibilities for solving the COVID-19 prevention problem. With this observation, this paper proposed a game theory-based COVID-19 close contact detecting method with edge computing collaboration, named GCDM. The GCDM method is an efficient method for detecting COVID-19 close contact infection with users’ location information. With the help of edge computing’s feature, the GCDM can deal with the detecting requirements of computing and storage and relieve the user privacy problem. Technically, as the game reaches equilibrium, the GCDM method can maximize close contact detection completion rate while minimizing the latency and cost of the evaluation process in a decentralized manner. The GCDM is described in detail and the performance of GCDM is analyzed theoretically. Extensive experiments were conducted and experimental results demonstrate the superior performance of GCDM over other three representative methods through comprehensive analysis.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">HPCC</abbr> </div> <div id="chen2023gcn" class="col-sm-8"> <div class="title">A GCN-based Model for Recommendation Using Local Differential Privacy Method</div> <div class="author"> Cheng Chen , Guoming Zhang, <em>Bowen Liu</em>, and <a href="https://cs.nju.edu.cn/douwanchun/index.htm" rel="external nofollow noopener" target="_blank">Wanchun Dou</a> </div> <div class="periodical"> <em>In 2023 IEEE International Conference on High Performance Computing &amp; Communications (<b>HPCC</b>)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Differential privacy (DP) aims to protect user privacy in the age of ubiquitous data collection through inserting perturbations and achieves great success in the area of recommender systems. However, current recommendation models based on differential privacy treat all users equally, but some users want stronger privacy-preserving while some users pay less attention on privacy and want more accurate recommendations. To overcome the above challenge, this paper proposes a new security recommendation model based on graph convolutional network. It allows the users to decide the level of privacy-preserving by them-selves. The proposed model utilizes a personalized-oriented local differential privacy during collecting user data to protect user data. Then a clustering denoising module rebuilds the connections between users and items by deleting unreliable feedback. In this way, users can adjust their level of privacy-preserving locally and meanwhile, the server can still provide accurate personalized recommendations to those who prefer better recommendation performance. This work conducts comprehensive experiments on several real-world benchmark datasets and the experimental results validate the effectiveness of the proposed model.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">UIC</abbr> </div> <div id="EdgeIRS" class="col-sm-8"> <div class="title">An Intelligent Resource Scheduling Method With Edge Channel Deployment for BPM.</div> <div class="author"> <em>Bowen Liu</em>, <a href="https://cs.nju.edu.cn/douwanchun/index.htm" rel="external nofollow noopener" target="_blank">Wanchun Dou</a>, Xiaokang Zhou , Xuyun Zhang, Lianyong Qi, Fei Dai, and Chaochao Chen. </div> <div class="periodical"> <em>In 19th IEEE International Conference on Ubiquitous Intelligence and Computing (<b>UIC, Awards Outstanding Paper</b>)</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Edge computing is a novel computing paradigm that offers kinds of resources at the network edge. In edge computing, terminal users are connected to edge servers via the wireless network and there are various channels in each wireless link. These wireless channels are limited resource while different channel has different cost and service ability. The dynamic changes of users’ status make it harder to find an appropriate method to satisfy the BPM requirements of channel deployment. With this observation, it is a tricky challenge to make a trade-off between the system cost(rental price) and the service ability(number of users). In view of this challenge, an intelligent resource scheduling method, named EdgeIRS, is proposed in this paper. In the technical sense, the EdgeIRS method can accommodate most users at the edge with a minimum cost of deploying channel resources in an online way. Its performance is analyzed theoretically and the experiments verify the superiority of the method.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Bowen LIU . Last updated: June 07, 2025. </div> </footer> <style>.clustrmaps-wrapper{margin:2rem auto 1rem;padding-top:2rem;border-top:1px solid var(--global-divider-color)}@media(max-width:768px){.clustrmaps-wrapper{margin:2rem -1rem;padding-top:1.5rem}}.clustrmaps-wrapper{transition:all .3s ease}</style> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">
      window.MathJax = {
        tex: {
          tags: 'ams',
        },
      };
    </script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">
    /*
     * This JavaScript code has been adapted from the article
     * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar,
     * published on the website https://css-tricks.com on the 7th of May, 2014.
     * Couple of changes were made to the original code to make it compatible
     * with the `al-foio` theme.
     */
    const progressBar = $('#progress');
    /*
     * We set up the bar after all elements are done loading.
     * In some cases, if the images in the page are larger than the intended
     * size they'll have on the page, they'll be resized via CSS to accomodate
     * the desired size. This mistake, however, breaks the computations as the
     * scroll size is computed as soon as the elements finish loading.
     * To account for this, a minimal delay was introduced before computing the
     * values.
     */
    window.onload = function () {
      setTimeout(progressBarSetup, 50);
    };
    /*
     * We set up the bar according to the browser.
     * If the browser supports the progress element we use that.
     * Otherwise, we resize the bar thru CSS styling
     */
    function progressBarSetup() {
      if ('max' in document.createElement('progress')) {
        initializeProgressElement();
        $(document).on('scroll', function () {
          progressBar.attr({ value: getCurrentScrollPosition() });
        });
        $(window).on('resize', initializeProgressElement);
      } else {
        resizeProgressBar();
        $(document).on('scroll', resizeProgressBar);
        $(window).on('resize', resizeProgressBar);
      }
    }
    /*
     * The vertical scroll position is the same as the number of pixels that
     * are hidden from view above the scrollable area. Thus, a value > 0 is
     * how much the user has scrolled from the top
     */
    function getCurrentScrollPosition() {
      return $(window).scrollTop();
    }

    function initializeProgressElement() {
      let navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      progressBar.css({ top: navbarHeight });
      progressBar.attr({
        max: getDistanceToScroll(),
        value: getCurrentScrollPosition(),
      });
    }
    /*
     * The offset between the html document height and the browser viewport
     * height will be greater than zero if vertical scroll is possible.
     * This is the distance the user can scroll
     */
    function getDistanceToScroll() {
      return $(document).height() - $(window).height();
    }

    function resizeProgressBar() {
      progressBar.css({ width: getWidthPercentage() + '%' });
    }
    // The scroll ratio equals the percentage to resize the bar
    function getWidthPercentage() {
      return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
    }
  </script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>
    let searchTheme = determineComputedTheme();
    const ninjaKeys = document.querySelector('ninja-keys');

    if (searchTheme === 'dark') {
      ninjaKeys.classList.add('dark');
    } else {
      ninjaKeys.classList.remove('dark');
    }

    const openSearchModal = () => {
      // collapse navbarNav if expanded on mobile
      const $navbarNav = $('#navbarNav');
      if ($navbarNav.hasClass('show')) {
        $navbarNav.collapse('hide');
      }
      ninjaKeys.open();
    };
  </script> <script>
    // get the ninja-keys element
    const ninja = document.querySelector('ninja-keys');

    // add the home and posts menu items
    ninja.data = [{
        id: "nav-about",
        title: "About",
        section: "Navigation",
        handler: () => {
          window.location.href = "/";
        },
      },{id: "nav-publications",
              title: "Publications",
              description: "* denotes equal contribution.",
              section: "Navigation",
              handler: () => {
                window.location.href = "/publications/";
              },
            },{id: "nav-cv",
              title: "CV",
              description: "",
              section: "Navigation",
              handler: () => {
                window.location.href = "/cv/";
              },
            },{id: "news-edgeirs-won-the-distinguished-paper-award-at-uic-2022",
              title: 'EdgeIRS won the Distinguished Paper Award at UIC 2022!',
              description: "",
              section: "News",},{id: "news-edgeshield-is-accepted-to-tmc-2024",
              title: 'EdgeShield is accepted to TMC 2024!',
              description: "",
              section: "News",},{id: "news-cause-is-accepted-to-s-amp-amp-p-2025",
              title: 'CAUSE is accepted to S&amp;amp;P 2025!',
              description: "",
              section: "News",},{id: "news-fuselink-is-accepted-to-osdi-2025",
              title: 'FuseLink is accepted to OSDI 2025!',
              description: "",
              section: "News",},{id: "news-carc-is-accepted-to-apnet-2025",
              title: 'CARC is accepted to APNet 2025!',
              description: "",
              section: "News",},{id: "news-flb-is-accepted-to-atc-2025",
              title: 'FLB is accepted to ATC 2025!',
              description: "",
              section: "News",},{id: "news-ceio-and-dcp-are-accepted-to-sigcomm-2025",
              title: 'CEIO and DCP are accepted to SIGCOMM 2025!',
              description: "",
              section: "News",},{id: "projects-project-1",
              title: 'project 1',
              description: "with background image",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/1_project/";
                },},{id: "projects-project-2",
              title: 'project 2',
              description: "a project with a background image and giscus comments",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/2_project/";
                },},{id: "projects-project-3-with-very-long-name",
              title: 'project 3 with very long name',
              description: "a project that redirects to another website",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/3_project/";
                },},{id: "projects-project-4",
              title: 'project 4',
              description: "another without an image",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/4_project/";
                },},{id: "projects-project-5",
              title: 'project 5',
              description: "a project with a background image",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/5_project/";
                },},{id: "projects-project-6",
              title: 'project 6',
              description: "a project with no image",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/6_project/";
                },},{id: "projects-project-7",
              title: 'project 7',
              description: "with background image",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/7_project/";
                },},{id: "projects-project-8",
              title: 'project 8',
              description: "an other project with a background image and giscus comments",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/8_project/";
                },},{id: "projects-project-9",
              title: 'project 9',
              description: "another project with an image 🎉",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/9_project/";
                },},{
            id: 'socials-email',
            title: 'Send email',
            section: 'Socials',
            handler: () => {
              window.open("mailto:%6C%69%75%62%77@%75%73%74.%68%6B", "_blank");
            },
          },{
            id: 'socials-google-scholar',
            title: 'Google Scholar',
            section: 'Socials',
            handler: () => {
              window.open("https://scholar.google.com/citations?user=Vi3kKvIAAAAJ", "_blank");
            },
          },{
            id: 'socials-github',
            title: 'GitHub',
            section: 'Socials',
            handler: () => {
              window.open("https://github.com/AlbertBowen", "_blank");
            },
          },{
          id: 'light-theme',
          title: 'Change theme to light',
          description: 'Change the theme of the site to Light',
          section: 'Theme',
          handler: () => {
            setThemeSetting("light");
          },
        },
        {
          id: 'dark-theme',
          title: 'Change theme to dark',
          description: 'Change the theme of the site to Dark',
          section: 'Theme',
          handler: () => {
            setThemeSetting("dark");
          },
        },
        {
          id: 'system-theme',
          title: 'Use system default theme',
          description: 'Change the theme of the site to System Default',
          section: 'Theme',
          handler: () => {
            setThemeSetting("system");
          },
        },];
  </script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>